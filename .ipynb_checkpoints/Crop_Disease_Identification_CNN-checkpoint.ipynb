{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81520f2",
   "metadata": {},
   "source": [
    "# üåø Crop Disease Identification Using CNN\n",
    "\n",
    "## üéØ Objective\n",
    "This project uses a Convolutional Neural Network (CNN) to classify crop leaf images as healthy or diseased.  \n",
    "It is based on the PlantVillage dataset and supports deployment through a Flask web interface.\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è Table of Contents\n",
    "1. [Importing Libraries](#importing-libraries)\n",
    "2. [Data Loading](#data-loading)\n",
    "3. [Image Preprocessing](#image-preprocessing)\n",
    "4. [CNN Model Building](#cnn-model-building)\n",
    "5. [Model Training](#model-training)\n",
    "6. [Evaluation](#evaluation)\n",
    "7. [Model Saving](#model-saving)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8173d1c5",
   "metadata": {},
   "source": [
    "## 1. üì¶ Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6b8eb",
   "metadata": {},
   "source": [
    "## 2. üìÇ Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'PlantVillage'  # Replace with actual folder path\n",
    "img_height, img_width = 128, 128\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bea5d",
   "metadata": {},
   "source": [
    "## 3. üßº Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "class_labels = list(train_generator.class_indices.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e37a79",
   "metadata": {},
   "source": [
    "## 4. üß† CNN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2aea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166018ab",
   "metadata": {},
   "source": [
    "## 5. üèãÔ∏è‚Äç‚ôÄÔ∏è Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd82905",
   "metadata": {},
   "source": [
    "## 6. üìà Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25715f0",
   "metadata": {},
   "source": [
    "## 7. üíæ Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1064e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('crop_disease_app/model/crop_model.h5')\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
